{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://S7-13-035008.group.s7:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20bb8026808>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = spark.read.parquet(\"test.parquet\")\n",
    "trainingData = spark.read.parquet(\"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+---------+------+------+----------------+---------+-----------------+\n",
      "|ad_id|target_audience_count|has_video|is_cpm|is_cpc|         ad_cost|day_count|              ctr|\n",
      "+-----+---------------------+---------+------+------+----------------+---------+-----------------+\n",
      "|    6|     11418.7085911347|        1|     1|     0|204.104562956739|       11|0.909738306804039|\n",
      "|   11|     9637.20484730933|        1|     1|     0|192.092306095236|       18| 1.02222752080496|\n",
      "|   12|     9886.86231469735|        1|     1|     0|199.987605376721|       15| 1.02822730862374|\n",
      "|   21|     9568.62828947957|        1|     1|     0|199.557502134239|       11| 1.23608059326114|\n",
      "|   24|     8891.97983774145|        1|     1|     0|199.158928072324|       15| 1.25439490657975|\n",
      "|   27|     9147.65018866017|        1|     1|     0|196.168514471689|       14| 1.30790620835937|\n",
      "|   38|     10134.2838536135|        1|     1|     0| 199.27560146114|       15| 1.40625464282379|\n",
      "|   45|     9009.48920578631|        1|     1|     0|194.621120338202|       17| 1.43921949357006|\n",
      "|   47|     9874.31181906214|        1|     1|     0|201.385290138343|       17| 1.47600831124599|\n",
      "|   49|     9604.62085897667|        1|     1|     0|200.786034118613|       12| 1.49335684310573|\n",
      "|   60|     9147.81344039761|        1|     1|     0|199.050187317005|       16| 1.52951605377533|\n",
      "|   61|     8591.78527314758|        1|     1|     0|202.284913100028|       12| 1.54507594465651|\n",
      "|   62|     8906.72657406149|        1|     1|     0|198.458577930758|       15| 1.55096136154763|\n",
      "|   66|     9278.26821667383|        1|     1|     0|197.574676558419|       16| 1.57510112985433|\n",
      "|   67|      9388.1555670989|        1|     1|     0|198.304757437614|       19| 1.58441589560377|\n",
      "|   79|     9006.50412553206|        1|     1|     0|199.380071447622|       14| 1.60497284808644|\n",
      "|   81|     8687.42448640074|        1|     1|     0|202.668726040696|       14| 1.60761579962092|\n",
      "|   82|     9730.35670907323|        1|     1|     0|200.769173317311|       15| 1.60928235991465|\n",
      "|   84|     9336.23773978338|        1|     1|     0|198.570809566171|       19| 1.61044240312088|\n",
      "|   87|     8541.00841642727|        1|     1|     0|202.846306361605|       14| 1.64634162428989|\n",
      "+-----+---------------------+---------+------+------+----------------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 79932 training examples and 19999 validate examples.\n"
     ]
    }
   ],
   "source": [
    "train, validate = trainingData.randomSplit([0.8, 0.2])\n",
    "print(\"We have %d training examples and %d validate examples.\" % (train.count(), validate.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=trainingData.columns[1:-1],outputCol=\"rawfeatures\")\n",
    "indexed_feature = VectorIndexer(inputCol=\"rawfeatures\", outputCol=\"features\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on our test set: 0.257065\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(labelCol=\"ctr\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_gbt = Pipeline(stages=[feature, indexed_feature, gbt])\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "              .addGrid(gbt.maxDepth, [2, 5])\\\n",
    "              .addGrid(gbt.maxIter, [10])\\\n",
    "              .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ctr\", predictionCol=\"prediction\")\n",
    "cv = TrainValidationSplit(estimator=pipeline_gbt, evaluator=evaluator, estimatorParamMaps=paramGrid,trainRatio=0.8)\n",
    "\n",
    "gbt_model = cv.fit(train)\n",
    "#gbt_best_model = gbt_model.bestModel\n",
    "gbt_predictions = gbt_model.transform(validate)\n",
    "\n",
    "rmse_gbt = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(\"RMSE on our test set: %g\" % rmse_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on our test set: 0.299541\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(labelCol=\"ctr\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[feature, indexed_feature, rf])\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder()\\\n",
    "               .addGrid(rf.maxDepth, [2, 5, 10])\\\n",
    "               .addGrid(rf.maxBins, [5, 10, 20])\\\n",
    "               .addGrid(rf.numTrees, [5, 20, 50])\\\n",
    "               .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ctr\", predictionCol=\"prediction\")\n",
    "\n",
    "cv_rf = TrainValidationSplit(estimator=pipeline_rf, evaluator=evaluator, estimatorParamMaps=paramGrid_rf,trainRatio=0.8)\n",
    "\n",
    "rf_model = cv_rf.fit(train)\n",
    "rf_best_model = rf_model.bestModel\n",
    "rf_predictions = rf_best_model.transform(validate)\n",
    "\n",
    "rmse_rf = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(\"RMSE on our test set: %g\" % rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on our dtr test set: 0.255257\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(labelCol=\"ctr\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_dtr = Pipeline(stages=[feature, indexed_feature, dtr])\n",
    "\n",
    "paramGrid_dtr = ParamGridBuilder()\\\n",
    "                 .addGrid(dtr.maxDepth, [2, 5, 10, 20, 30])\\\n",
    "                 .addGrid(dtr.maxBins, [10, 20, 40, 80, 100])\\\n",
    "                 .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ctr\", predictionCol=\"prediction\")\n",
    "tvs_dtr = TrainValidationSplit(estimator=pipeline_dtr, evaluator=evaluator, estimatorParamMaps=paramGrid_dtr,trainRatio=0.8)\n",
    "\n",
    "dtr_model = tvs_dtr.fit(train)\n",
    "dtr_best_model = dtr_model.bestModel\n",
    "\n",
    "dtr_predictions = dtr_best_model.transform(validate)\n",
    "rmse_dtr = evaluator.evaluate(dtr_predictions)\n",
    "print(\"RMSE on our dtr test set: %g\" % rmse_dtr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_best_model.write().overwrite().save('dtr_best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelineModel.load('dtr_best_model')\n",
    "dtr_best_model.transform(testData)\\\n",
    "            .select(\"ad_id\",\"prediction\")\\\n",
    "            .coalesce(1)\\\n",
    "            .write.csv(result+\"/our_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5\n"
     ]
    }
   ],
   "source": [
    "# print('Num Trees: {}'.format(model.bestModel._java_obj.getRegParam()))\n",
    "print('Max Depth: {}'.format(dtr_model.bestModel.stages[-1]._java_obj.getMaxDepth()))\n",
    "# print('Impurity: {}'.format(model.bestModel._java_obj.getImpurity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.412181\n",
      "r2: 0.829792\n"
     ]
    }
   ],
   "source": [
    "feature_lg = VectorAssembler(inputCols=train.columns[:-1],outputCol=\"features\")\n",
    "feature_vector = feature_lg.transform(train)\n",
    "lr = LinearRegression(maxIter=40, regParam=0.4, elasticNetParam=0.8,labelCol = 'ctr')\n",
    "lrModel = lr.fit(feature_vector)\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
